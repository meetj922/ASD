{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG19, Xception, InceptionV3, MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "photo_size = 224\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "def prepare_dataset(data_dir, num_images, subset=None):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(photo_size, photo_size),\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        classes=['non_autistic', 'autistic'],\n",
    "        shuffle=True,\n",
    "        subset=subset\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# Function to define and train model with learning rate scheduler\n",
    "def train_model_with_lr_scheduler(base_model_fn, model_name, train_images, val_images, test_images):\n",
    "    # Create base model\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=(photo_size, photo_size, 3))\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add kayers for binary classification\n",
    "    flat = Flatten()(base_model.output)\n",
    "    dense1 = Dense(256, activation='relu')(flat)\n",
    "    batch_norm1 = BatchNormalization()(dense1)\n",
    "    dense2 = Dense(128, activation='relu')(batch_norm1)\n",
    "    batch_norm2 = BatchNormalization()(dense2)\n",
    "    output = Dense(1, activation='sigmoid')(batch_norm2)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_data = prepare_dataset('C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/train', train_images, subset='training')\n",
    "    validation_data = prepare_dataset('C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid', val_images)\n",
    "    test_data = prepare_dataset('C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/test', test_images)\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    \n",
    "    # Train model with early stopping and learning rate scheduler\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    # Evaluate model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_data)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(\"{}.h5\".format(model_name))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Number of images in train, validation, and test sets\n",
    "train_images = 2540\n",
    "val_images = 300\n",
    "test_images = 300\n",
    "\n",
    "# Train VGG19 model with learning rate scheduler\n",
    "vgg19_model, vgg19_history = train_model_with_lr_scheduler(VGG19, 'vgg19_lr_scheduler', train_images, val_images, test_images)\n",
    "\n",
    "# Train Xception model with learning rate scheduler\n",
    "xception_model, xception_history = train_model_with_lr_scheduler(Xception, 'xception_lr_scheduler', train_images, val_images, test_images)\n",
    "\n",
    "# Train InceptionV3 model with learning rate scheduler\n",
    "inception_model, inception_history = train_model_with_lr_scheduler(InceptionV3, 'inception_lr_scheduler', train_images, val_images, test_images)\n",
    "\n",
    "# Train MobileNet model with learning rate scheduler\n",
    "mobilenet_model, mobilenet_history = train_model_with_lr_scheduler(MobileNet, 'mobilenet_lr_scheduler', train_images, val_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training history of the MobileNet model\n",
    "history = vgg19_history.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the VGG19 model\n",
    "vgg19_model = tf.keras.models.load_model(\"vgg19_lr_scheduler.h5\")\n",
    "\n",
    "# Define image size expected by the model\n",
    "photo_size = 224\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get true label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Preprocess the image\n",
    "                processed_image = preprocess_image(image_path)\n",
    "                # Make prediction\n",
    "                prediction = vgg19_model.predict(processed_image)[0][0]  # Extracting the single prediction value\n",
    "                # Assign predicted label based on prediction threshold (0.5)\n",
    "                predicted_label = 1 if prediction >= 0.5 else 0\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training history of the MobileNet model\n",
    "history = xception_history.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the VGG19 model\n",
    "vgg19_model = tf.keras.models.load_model(\"xception_lr_scheduler.h5\")\n",
    "\n",
    "# Define image size expected by the model\n",
    "photo_size = 224\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get true label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Preprocess the image\n",
    "                processed_image = preprocess_image(image_path)\n",
    "                # Make prediction\n",
    "                prediction = vgg19_model.predict(processed_image)[0][0]  # Extracting the single prediction value\n",
    "                # Assign predicted label based on prediction threshold (0.5)\n",
    "                predicted_label = 1 if prediction >= 0.5 else 0\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training history of the MobileNet model\n",
    "history = inception_history.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the VGG19 model\n",
    "vgg19_model = tf.keras.models.load_model(\"inception_lr_scheduler.h5\")\n",
    "\n",
    "# Define image size expected by the model\n",
    "photo_size = 224\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get true label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Preprocess the image\n",
    "                processed_image = preprocess_image(image_path)\n",
    "                # Make prediction\n",
    "                prediction = vgg19_model.predict(processed_image)[0][0]  # Extracting the single prediction value\n",
    "                # Assign predicted label based on prediction threshold (0.5)\n",
    "                predicted_label = 1 if prediction >= 0.5 else 0\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training history of the MobileNet model\n",
    "history = mobilenet_history.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the VGG19 model\n",
    "vgg19_model = tf.keras.models.load_model(\"mobilenet_lr_scheduler.h5\")\n",
    "\n",
    "# Define image size expected by the model\n",
    "photo_size = 224\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get true label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Preprocess the image\n",
    "                processed_image = preprocess_image(image_path)\n",
    "                # Make prediction\n",
    "                prediction = vgg19_model.predict(processed_image)[0][0]  # Extracting the single prediction value\n",
    "                # Assign predicted label based on prediction threshold (0.5)\n",
    "                predicted_label = 1 if prediction >= 0.5 else 0\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define image size expected by the models\n",
    "photo_size = 224\n",
    "\n",
    "# Load the saved models\n",
    "vgg19_model = tf.keras.models.load_model(\"vgg19_lr_scheduler.h5\")\n",
    "mobilenet_model = tf.keras.models.load_model(\"mobilenet_lr_scheduler.h5\")\n",
    "\n",
    "# Define weights for the models\n",
    "vgg19_weight = 0.6\n",
    "mobilenet_weight = 0.4\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to make predictions using weighted average\n",
    "def make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight):\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    # Make predictions using both models\n",
    "    vgg19_prediction = vgg19_model.predict(processed_image)[0][0]\n",
    "    mobilenet_prediction = mobilenet_model.predict(processed_image)[0][0]\n",
    "    # Combine predictions using weighted average\n",
    "    weighted_prediction = (vgg19_weight * vgg19_prediction) + (mobilenet_weight * mobilenet_prediction)\n",
    "    return weighted_prediction\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Initialize lists to store ground truth labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get ground truth label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Make weighted prediction\n",
    "                prediction = make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight)\n",
    "                predictions.append(prediction)\n",
    "\n",
    "# Convert lists to arrays for accuracy calculation\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions.round())\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Define image size expected by the models\n",
    "photo_size = 224\n",
    "\n",
    "# Load the saved models\n",
    "vgg19_model = tf.keras.models.load_model(\"vgg19_lr_scheduler.h5\")\n",
    "mobilenet_model = tf.keras.models.load_model(\"mobilenet_lr_scheduler.h5\")\n",
    "\n",
    "# Define weights for the models\n",
    "vgg19_weight = 0.6\n",
    "mobilenet_weight = 0.4\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to make predictions using weighted average\n",
    "def make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight):\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    # Make predictions using both models\n",
    "    vgg19_prediction = vgg19_model.predict(processed_image)[0][0]\n",
    "    mobilenet_prediction = mobilenet_model.predict(processed_image)[0][0]\n",
    "    # Combine predictions using weighted average\n",
    "    weighted_prediction = (vgg19_weight * vgg19_prediction) + (mobilenet_weight * mobilenet_prediction)\n",
    "    return weighted_prediction\n",
    "\n",
    "# Define ground truth labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = \"C:/Users/meetj/OneDrive/Desktop/ASD/AutismDataset/valid\"\n",
    "\n",
    "# Iterate through all image files in the folder\n",
    "for subdir in os.listdir(image_folder):\n",
    "    if os.path.isdir(os.path.join(image_folder, subdir)):\n",
    "        for filename in os.listdir(os.path.join(image_folder, subdir)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(image_folder, subdir, filename)\n",
    "                # Get ground truth label from folder name\n",
    "                true_label = 1 if subdir == \"Autistic\" else 0\n",
    "                true_labels.append(true_label)\n",
    "                # Make weighted prediction\n",
    "                prediction = make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight)\n",
    "                predictions.append(prediction)\n",
    "\n",
    "# Convert lists to arrays for classification report\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Round predictions to 0 or 1\n",
    "rounded_predictions = np.round(predictions)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, rounded_predictions, target_names=['Non_Autistic', 'Autistic'])\n",
    "\n",
    "# Calculate accuracy and loss\n",
    "accuracy = np.mean(true_labels == rounded_predictions)\n",
    "loss = np.mean(tf.keras.losses.binary_crossentropy(true_labels, predictions))\n",
    "\n",
    "# Print classification report, accuracy, and loss\n",
    "print(report)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Loss:\", loss)\n",
    "\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(true_labels, label='True Labels')\n",
    "plt.plot(rounded_predictions, label='Predictions')\n",
    "plt.title('Accuracy: Predictions vs True Labels')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predictions, label='Predictions')\n",
    "plt.plot(true_labels, label='True Labels')\n",
    "plt.title('Loss: Predictions vs True Labels')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Define image size expected by the models\n",
    "photo_size = 224\n",
    "\n",
    "# Load the saved models\n",
    "vgg19_model = tf.keras.models.load_model(\"vgg19_lr_scheduler.h5\")\n",
    "mobilenet_model = tf.keras.models.load_model(\"mobilenet_lr_scheduler.h5\")\n",
    "\n",
    "# Define weights for the models\n",
    "vgg19_weight = 0.6\n",
    "mobilenet_weight = 0.4\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize the image\n",
    "    img = load_img(image_path, target_size=(photo_size, photo_size))\n",
    "    # Convert image to array and normalize pixel values\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Expand dimensions to match model input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to make predictions using weighted average\n",
    "def make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight):\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    # Make predictions using both models\n",
    "    vgg19_prediction = vgg19_model.predict(processed_image)[0][0]\n",
    "    mobilenet_prediction = mobilenet_model.predict(processed_image)[0][0]\n",
    "    # Combine predictions using weighted average\n",
    "    weighted_prediction = (vgg19_weight * vgg19_prediction) + (mobilenet_weight * mobilenet_prediction)\n",
    "    return weighted_prediction\n",
    "\n",
    "# Function to interpret the prediction\n",
    "def interpret_prediction(prediction):\n",
    "    if prediction >= 0.5:\n",
    "        return \"Autistic\"\n",
    "    else:\n",
    "        return \"Not Autistic\"\n",
    "\n",
    "# Path to the single image you want to predict\n",
    "image_path = \"C:/Users/meetj/OneDrive/Desktop/ASD/Models/Predictions/Autistic.101.jpg\"  # Replace with the actual path\n",
    "\n",
    "# Make prediction for the single image\n",
    "prediction = make_weighted_prediction(image_path, vgg19_model, mobilenet_model, vgg19_weight, mobilenet_weight)\n",
    "result = interpret_prediction(prediction)\n",
    "print(\"Prediction for\", image_path, \":\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
